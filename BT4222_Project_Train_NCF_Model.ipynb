{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ca411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "import random\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk import pos_tag\n",
    "# from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b57e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "pd.set_option('display.max_columns', None)\n",
    "restaurants_data = pd.read_csv('restaurants_final.csv')\n",
    "restaurants_data.drop('Unnamed: 0', axis=1, inplace=True) ## remove after data correction\n",
    "print(restaurants_data.head())\n",
    "review_data = pd.read_csv('review_final.csv')\n",
    "print(review_data.head())\n",
    "users = pd.read_csv('PA_restaurant_user_with_loc.csv')\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c40f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_str(text):\n",
    "    try:\n",
    "        items = ast.literal_eval(text)\n",
    "        return ' '.join(items) if isinstance(items, list) else text\n",
    "    except Exception:\n",
    "        return text\n",
    "\n",
    "def create_full_description(df, text_features):\n",
    "    # Fill missing values\n",
    "    # features = text_features + bool_features\n",
    "    features = text_features\n",
    "    df[features] = df[features].fillna('')\n",
    "    \n",
    "    # Fill missing editorial_summary with types + categories (without commas)\n",
    "    df['editorial_summary'] = df['editorial_summary'].apply(lambda x: x if x.strip() != '' else '')\n",
    "    # df['types'] = df['types'].str.replace(',', ' ')\n",
    "    df['categories'] = df['categories'].str.replace(',', ' ')\n",
    "    df.loc[df['editorial_summary'].str.strip() == '', 'editorial_summary'] = (\n",
    "        df['categories']\n",
    "    )\n",
    "    \n",
    "    # Convert list-formatted column to plain text\n",
    "    # df[list_feature] = df[list_feature].apply(convert_list_str)\n",
    "\n",
    "    # Remove commas from all text features\n",
    "    for col in text_features:\n",
    "        df[col] = df[col].str.replace(',', ' ')\n",
    "    \n",
    "    # if len(bool_features) != 0:\n",
    "    #     # Convert boolean columns to descriptive tags\n",
    "    #     for col in bool_features:\n",
    "    #         df[col] = df[col].apply(lambda x: f\"{col.lower()}\" if x == True else \"\")\n",
    "        \n",
    "    # Combine all into a single description column\n",
    "    df['description'] = df[text_features]\\\n",
    "        .agg(' '.join, axis=1)\\\n",
    "        .str.replace(r'\\s+', ' ', regex=True)\\\n",
    "        .str.strip()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25822882",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = restaurants_data.copy() \n",
    "# text_features = ['categories', 'editorial_summary', 'types', 'city']\n",
    "text_features = ['categories', 'editorial_summary', 'city', 'name']\n",
    "# bool_features = [\n",
    "#             'OutdoorSeating', 'RestaurantsTakeOut', 'RestaurantsDelivery',\n",
    "#             'RestaurantsReservations', 'GoodForKids', 'RestaurantsGoodForGroups',\n",
    "#             'HappyHour', 'serves_breakfast', 'serves_lunch', 'serves_dinner',\n",
    "#             'serves_brunch', 'serves_beer', 'serves_wine', 'serves_cocktails',\n",
    "#             'serves_dessert', 'serves_coffee', 'BusinessAcceptsCreditCards', 'HasTV',\n",
    "#             'BikeParking', 'Caters', 'RestaurantsTableService',\n",
    "#         ]\n",
    "bool_features = []\n",
    "# list_features = ['parking_options']\n",
    "list_features = []\n",
    "# handle WiFi column\n",
    "# handle RestaurantsAttire column\n",
    "# handle BusinessParking column\n",
    "# handle NoiseLevel column\n",
    "# handle Ambience column\n",
    "# handle GoodForMeal column\n",
    "# remove WheelchairAccessible column\n",
    "# handle Alcohol column\n",
    "# handle DogsAllowed column\n",
    "\n",
    "\n",
    "\n",
    "item_df = create_full_description(item_df, text_features)\n",
    "# remove text features\n",
    "item_df = item_df.drop(text_features, axis=1)\n",
    "print(item_df[['business_id', 'description']].head())\n",
    "print(item_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_features = [\n",
    "            'OutdoorSeating', 'RestaurantsTakeOut', 'RestaurantsDelivery',\n",
    "            'RestaurantsReservations', 'GoodForKids', 'RestaurantsGoodForGroups',\n",
    "            'serves_breakfast', 'serves_lunch', 'serves_dinner',\n",
    "            'serves_brunch', 'serves_beer', 'serves_wine', 'serves_cocktails',\n",
    "            'serves_dessert', 'serves_coffee', 'BusinessAcceptsCreditCards',\n",
    "        ]\n",
    "\n",
    "# check for missing values in bool features\n",
    "print(item_df[bool_features].isnull().sum())\n",
    "# we remove HappyHour, HasTV, BikeParking, Caters, RestaurantsTableService due to the high number of missing values\n",
    "# confirm that these columns only contain true/false values\n",
    "print(item_df[bool_features].describe())\n",
    "# fill missing values with False (we assume that if the value is not present, it is False)\n",
    "item_df[bool_features] = item_df[bool_features].fillna(False)\n",
    "# convert bool features to int\n",
    "for col in bool_features:\n",
    "    item_df[col] = item_df[col].astype(int)\n",
    "\n",
    "print(item_df[bool_features].describe()) # confirm that these columns only contain 0/1 values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adb6ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the columns we need\n",
    "# item_df = item_df[['business_id', 'description'] + bool_features]\n",
    "item_df = item_df[['business_id'] + bool_features]\n",
    "print(item_df.shape)\n",
    "print(item_df.columns)\n",
    "print(item_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5409d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = review_data.copy()\n",
    "review_df['interaction'] = review_df['stars'].apply(lambda x: 1 if x >= 3 else 0)\n",
    "interaction_df = review_df[['user_id', 'business_id', 'stars', 'interaction', 'date']].copy()\n",
    "print(interaction_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880c739",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_user_features = ['review_count', 'useful', 'funny', 'cool', 'fans', 'average_stars', 'compliment_hot', 'compliment_more', 'compliment_profile',\n",
    "                           'compliment_cute', 'compliment_list', 'compliment_note', 'compliment_plain', 'compliment_writer', 'compliment_cool', \n",
    "                           'compliment_funny', 'compliment_photos', \"('latitude', 'mean')\", \"('longitude', 'mean')\"]\n",
    "# select only the columns we need\n",
    "user_df = users.copy()\n",
    "# not yet handled latitude and longitude\n",
    "user_df = user_df[['user_id'] + numerical_user_features]\n",
    "print(user_df.shape)\n",
    "\n",
    "# standardize numerical features to between 0 and 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "user_df[numerical_user_features] = scaler.fit_transform(user_df[numerical_user_features])\n",
    "print(user_df.head(2))\n",
    "print(user_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712bbd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample 100 users\n",
    "user_df = user_df.sample(1000, random_state=42)\n",
    "\n",
    "# combine user, restaurant and review data\n",
    "user_restaurant_review = pd.merge(interaction_df, item_df, on='business_id', how='left')\n",
    "user_restaurant_review = pd.merge(user_restaurant_review, user_df, on='user_id', how='right')\n",
    "print(user_restaurant_review.shape)\n",
    "print(user_restaurant_review.describe())\n",
    "print(user_restaurant_review.head(2))\n",
    "\n",
    "# remove name, yelping_since, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12870673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37371a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RestaurantRatingModel(nn.Module):\n",
    "    def __init__(self, num_users, num_restaurants, embedding_dim=32):\n",
    "        super(RestaurantRatingModel, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.restaurant_embedding = nn.Embedding(num_restaurants, embedding_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2*embedding_dim, 256), # 2x embedding_dim because we concatenate user and item embeddings\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, user, restaurant):\n",
    "        user_embedding = self.user_embedding(user)\n",
    "        restaurant_embedding = self.restaurant_embedding(restaurant)\n",
    "        concat = torch.cat([user_embedding, restaurant_embedding], dim=1)\n",
    "        output = self.mlp(concat)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe793be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RestaurantRatingModel(nn.Module):\n",
    "#     def __init__(self, num_users, num_restaurants, user_num_features, restaurant_num_features, embedding_dim=50):\n",
    "#         super(RestaurantRatingModel, self).__init__()\n",
    "        \n",
    "#         # User tower components\n",
    "#         self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "#         self.user_fc = nn.Linear(embedding_dim + user_num_features, 128)\n",
    "        \n",
    "#         # Restaurant tower components\n",
    "#         self.restaurant_embedding = nn.Embedding(num_restaurants, embedding_dim)\n",
    "#         self.restaurant_fc = nn.Linear(embedding_dim + restaurant_num_features, 128)\n",
    "\n",
    "#         # Review tower components\n",
    "#         self.review_embedding = nn.Embedding(num_reviews, embedding_dim)\n",
    "#         self.review_fc = nn.Linear(embedding_dim + review_num_features, 128)\n",
    "        \n",
    "#         # Combined MLP\n",
    "#         self.combined_fc1 = nn.Linear(256, 256)\n",
    "#         self.combined_fc2 = nn.Linear(256, 128)\n",
    "#         self.output = nn.Linear(128, 1)\n",
    "        \n",
    "#         # Activation function\n",
    "#         self.relu = nn.ReLU()\n",
    "        \n",
    "#     def forward(self, user_id, user_numerical, restaurant_id, restaurant_numerical):\n",
    "#         # User tower\n",
    "#         user_emb = self.user_embedding(user_id).squeeze(1)\n",
    "#         user_combined = torch.cat([user_emb, user_numerical], dim=1)\n",
    "#         user_out = self.relu(self.user_fc(user_combined))\n",
    "        \n",
    "#         # Restaurant tower\n",
    "#         restaurant_emb = self.restaurant_embedding(restaurant_id).squeeze(1)\n",
    "#         restaurant_combined = torch.cat([restaurant_emb, restaurant_numerical], dim=1)\n",
    "#         restaurant_out = self.relu(self.restaurant_fc(restaurant_combined))\n",
    "        \n",
    "#         # Combine towers\n",
    "#         merged = torch.cat([user_out, restaurant_out], dim=1)\n",
    "#         x = self.relu(self.combined_fc1(merged))\n",
    "#         x = self.relu(self.combined_fc2(x))\n",
    "#         output = self.output(x)\n",
    "        \n",
    "#         return output\n",
    "\n",
    "# You'll need to create a custom Dataset class for your data\n",
    "class RestaurantDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.user_ids = torch.tensor(dataframe['user_id_encoded'].values, dtype=torch.long)\n",
    "        # self.user_numerical = torch.FloatTensor(user_numerical)\n",
    "        self.restaurant_ids = torch.tensor(dataframe['business_id_encoded'].values, dtype=torch.long)\n",
    "        # self.restaurant_numerical = torch.FloatTensor(restaurant_numerical)\n",
    "        self.ratings = torch.tensor(dataframe['interaction'].values, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.restaurant_ids[idx], self.ratings[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924be751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode user_id and restaurant_id\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "restaurant_encoder = LabelEncoder()\n",
    "\n",
    "user_restaurant_review['user_id_encoded'] = user_encoder.fit_transform(user_restaurant_review['user_id'])\n",
    "user_restaurant_review['business_id_encoded'] = restaurant_encoder.fit_transform(user_restaurant_review['business_id'])\n",
    "\n",
    "train_df = user_restaurant_review[user_restaurant_review['date'] < '2021-01-01']\n",
    "test_df = user_restaurant_review[user_restaurant_review['date'] >= '2021-01-01']\n",
    "\n",
    "# remove date column\n",
    "train_df.drop(['date'], axis=1, inplace=True)\n",
    "test_df.drop(['date'], axis=1, inplace=True)\n",
    "\n",
    "train_dataset = RestaurantDataset(train_df)\n",
    "test_dataset = RestaurantDataset(test_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# train_X = train_df.drop(['stars', 'interaction'], axis=1)\n",
    "# train_y = train_df['interaction']\n",
    "# # train_y = train_df['stars']\n",
    "# # take only 5000 samples for training\n",
    "# train_X = train_X.sample(n=5000, random_state=42)\n",
    "# train_y = train_y[train_X.index]\n",
    "\n",
    "# # test_X = test_df.drop(['user_id', 'business_id', 'stars', 'interaction', 'date'], axis=1)\n",
    "# test_X = test_df.drop(['stars', 'interaction'], axis=1)\n",
    "# test_y = test_df['interaction']\n",
    "# # test_y = test_df['stars']\n",
    "# print(train_X.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1409b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Assuming you have prepared your data\n",
    "num_users = len(np.unique(user_restaurant_review['user_id_encoded']))\n",
    "num_restaurants = len(np.unique(user_restaurant_review['business_id_encoded']))\n",
    "user_num_features = len(numerical_user_features)\n",
    "restaurant_num_features = len(bool_features)\n",
    "\n",
    "model = RestaurantRatingModel(\n",
    "    num_users=num_users,\n",
    "    num_restaurants=num_restaurants,\n",
    "    # user_num_features=user_num_features,\n",
    "    # restaurant_num_features=restaurant_num_features,\n",
    "    embedding_dim= 64\n",
    ")\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e88577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example training loop\n",
    "def train(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch in dataloader:\n",
    "            user, item, label = batch\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(user, item)\n",
    "            loss = criterion(outputs.squeeze(), label)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}')\n",
    "        evaluate_model(model, test_loader)\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            user, item, label = batch\n",
    "            outputs = model(user, item)\n",
    "            predicted = (outputs.squeeze() >= 0.5).float()  # Assuming binary classification\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d962351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train(model, train_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7034ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     [train_X['user_id'], train_X[user_num_features], train_X['business_id'], train_X[restaurant_num_features]],\n",
    "#     train_y,\n",
    "#     validation_data=([test_X['user_id'], test_X[user_num_features], test_X['business_id'], test_X[restaurant_num_features]], test_y),\n",
    "#     epochs=10, batch_size=64\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85566674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recommend_top_restaurants(user_id, model, restaurants_data, user_features):\n",
    "#     user_data = user_features[user_features['user_id'] == user_id].iloc[0]\n",
    "#     user_inputs = np.array([user_id]), user_data[user_num_features].values.reshape(1, -1)\n",
    "    \n",
    "#     restaurant_scores = []\n",
    "#     for _, restaurant in restaurants_data.iterrows():\n",
    "#         restaurant_inputs = np.array([restaurant['business_id']]), restaurant[restaurant_num_features].values.reshape(1, -1)\n",
    "#         score = model.predict([user_inputs[0], user_inputs[1], restaurant_inputs[0], restaurant_inputs[1]])\n",
    "#         restaurant_scores.append((restaurant['business_id'], score))\n",
    "    \n",
    "#     # Sort and select top 10\n",
    "#     restaurant_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "#     return restaurant_scores[:10]\n",
    "\n",
    "# # Example usage\n",
    "# # top_restaurants = recommend_top_restaurants(user_id=\"X88LNRDRZ_1TooB71AIgpA\", model=model, restaurants_data=item_df, user_features=user_df)\n",
    "# # print(\"Top 10 Recommendations:\", top_restaurants)\n",
    "\n",
    "# def evaluate_model(model, test_X, test_y):\n",
    "#     predictions = model.predict([test_X['user_id'], test_X[user_numerical_features], test_X['business_id'], test_X[restaurant_numerical_features]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f667e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run evaluations with NDCG@10, Precision@10\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score, precision_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "def evaluate_model_final(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            user, item, label = batch\n",
    "            outputs = model(user, item)\n",
    "            predicted = (outputs.squeeze() >= 0.5).float()  # Assuming binary classification\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "            predictions.extend(outputs.squeeze().numpy())\n",
    "            labels.extend(label.numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "    rmse = np.sqrt(mean_squared_error(labels, predictions))\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    ndcg = ndcg_score([labels], [predictions], k=10)\n",
    "    print(f\"NDCG@10: {ndcg:.4f}\")\n",
    "    # precision = precision_score([labels], [predictions])\n",
    "    # print(f\"Precision@10: {precision:.4f}\")\n",
    "\n",
    "\n",
    "    # predictions = model.predict([test_X['user_id'], test_X['business_id']])\n",
    "    # predictions = predictions.flatten()\n",
    "    # rmse = np.sqrt(mean_squared_error(test_y, predictions))\n",
    "    # print(f\"RMSE: {rmse:.4f}\")\n",
    "    # ndcg = ndcg_score([test_y], [predictions], k=10)\n",
    "    # print(f\"NDCG@10: {ndcg:.4f}\")\n",
    "    # precision = precision_score([test_y], [predictions], k=10)\n",
    "    # print(f\"Precision@10: {precision:.4f}\")\n",
    "    # return rmse, ndcg, precision\n",
    "\n",
    "evaluate_model_final(model, test_loader)\n",
    "\n",
    "# rmse = evaluate_model(model, test_X, test_y)\n",
    "# print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# # calculate NDCG@10\n",
    "# ndcg = ndcg_score([test_y], [predictions], k=10)\n",
    "# print(f\"NDCG@10: {ndcg:.4f}\")\n",
    "\n",
    "# # calculate Precision@10\n",
    "# precision = precision_score([test_y], [predictions], k=10)\n",
    "# print(f\"Precision@10: {precision:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf44209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation(user_id, k=10):\n",
    "    model.eval()\n",
    "    user_restaurant_review_specific = user_restaurant_review[user_restaurant_review['user_id'] == user_id]\n",
    "    dataset = RestaurantDataset(user_restaurant_review_specific)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # get predictions for all restaurants\n",
    "    restaurant_scores = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            user, item, _ = batch\n",
    "            outputs = model(user, item)\n",
    "            restaurant_scores.append((item.item(), outputs.item()))\n",
    "\n",
    "    # sort by predicted rating\n",
    "    restaurant_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    # get top k restaurants\n",
    "    recommended_restaurants = restaurant_scores[:k]\n",
    "    # convert to DataFrame\n",
    "    recommended_restaurants_df = pd.DataFrame(recommended_restaurants, columns=['business_id_encoded', 'predicted_rating'])\n",
    "    # add business_id\n",
    "    recommended_restaurants_df['business_id'] = restaurant_encoder.inverse_transform(recommended_restaurants_df['business_id_encoded'])\n",
    "    return recommended_restaurants_df\n",
    "\n",
    "def hits_at_k(user_id, test_df, recommend_func, k=10):\n",
    "    # true_item = test_df.loc[test_df['user_id'] == user_id]['business_id'].iloc[0]\n",
    "    true_items = test_df[(test_df['user_id'] == user_id) &\n",
    "                         # Hit rate should consider if the user liked the restaurant\n",
    "                         (test_df['interaction'] == 1)\n",
    "                         ]['business_id'].tolist()\n",
    "    recommended = recommend_func(user_id, k)\n",
    "\n",
    "    recommended_items = recommended['business_id'].tolist()\n",
    "\n",
    "    return int(any(item in recommended_items for item in true_items))\n",
    "\n",
    "def plot_hit_rate_vs_users(test_df, max_users, step):\n",
    "    # Step 1: Get users sorted by interaction count descending\n",
    "    user_interaction_counts = (\n",
    "        test_df.groupby('user_id')\n",
    "        .size()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    sorted_users = user_interaction_counts.index.tolist()\n",
    "\n",
    "\n",
    "    # Step 2: Loop with cumulative hit calculation\n",
    "    hit_rates = []\n",
    "    total_hits = 0\n",
    "    evaluated_users = 0\n",
    "\n",
    "    for i in range(step, max_users + 1, step):\n",
    "        current_batch = sorted_users[evaluated_users:i]\n",
    "        hits_in_batch = sum(\n",
    "            hits_at_k(user, test_df, get_recommendation, k=10)\n",
    "            for user in current_batch\n",
    "        )\n",
    "        total_hits += hits_in_batch\n",
    "        evaluated_users = i\n",
    "        hit_rate = total_hits / evaluated_users\n",
    "        hit_rates.append(hit_rate)\n",
    "\n",
    "    # Step 3: Plot\n",
    "    n_users_range = list(range(step, max_users + 1, step))\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    print(n_users_range, hit_rates)\n",
    "    plt.plot(n_users_range, hit_rates, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel(\"Number of Top Users (by Interactions)\")\n",
    "    plt.ylabel(\"Hit Rate@10\")\n",
    "    plt.title(\"Hit Rate vs. Number of Included Users\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0801a49a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# torch.set_default_tensor_type(torch.FloatTensor)  # force CPU tensors\n",
    "# model = model.cpu()\n",
    "\n",
    "plot_hit_rate_vs_users(test_df, max_users=1000, step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41958d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
